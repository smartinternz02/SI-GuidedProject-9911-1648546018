{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fea00caf",
   "metadata": {},
   "source": [
    "# Image Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "317439a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68eb30c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1/255,zoom_range=0.2,horizontal_flip=True,vertical_flip=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b88f82ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54573efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2520 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "x_train = train_datagen.flow_from_directory(r'E:\\vitExternship\\DataSet\\RPS_Dataset\\Training',target_size=(64,64),\n",
    "                                           class_mode='categorical',batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2760658a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0680bd5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 372 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "x_test = train_datagen.flow_from_directory(r'E:\\vitExternship\\DataSet\\RPS_Dataset\\Testing',target_size=(64,64),\n",
    "                                           class_mode='categorical',batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e3b8bd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'paper': 0, 'rock': 1, 'scissors': 2}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240ca602",
   "metadata": {},
   "source": [
    "# Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ac47a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Convolution2D, MaxPooling2D, Flatten, Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3060ed5",
   "metadata": {},
   "source": [
    "# Creating a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f9ffe93",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4f9495",
   "metadata": {},
   "source": [
    "# Adding Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff741fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convulation Layer\n",
    "model.add(Convolution2D(32,(3,3),activation='relu',input_shape=(64,64,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ebb103b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pooling Layer\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2389f869",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Flattening Layer\n",
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f13b0810",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hidden Layer1\n",
    "model.add(Dense(300,activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c7c7673",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hidden Layer2\n",
    "model.add(Dense(300,activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "89922e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Output Layer\n",
    "model.add(Dense(3,activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085dee0f",
   "metadata": {},
   "source": [
    "# Compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "262e5176",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db50336e",
   "metadata": {},
   "source": [
    "# Fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "757130ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\santh\\AppData\\Local\\Temp/ipykernel_2988/234118701.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(x_train,steps_per_epoch=len(x_train),epochs=10,validation_data=x_test,validation_steps=len(x_test))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "26/26 [==============================] - 13s 493ms/step - loss: 1.3205 - accuracy: 0.4099 - val_loss: 1.0059 - val_accuracy: 0.4677\n",
      "Epoch 2/10\n",
      "26/26 [==============================] - 12s 448ms/step - loss: 0.6244 - accuracy: 0.8024 - val_loss: 0.6927 - val_accuracy: 0.6935\n",
      "Epoch 3/10\n",
      "26/26 [==============================] - 12s 463ms/step - loss: 0.2560 - accuracy: 0.9393 - val_loss: 0.6111 - val_accuracy: 0.7339\n",
      "Epoch 4/10\n",
      "26/26 [==============================] - 12s 443ms/step - loss: 0.1434 - accuracy: 0.9591 - val_loss: 0.5085 - val_accuracy: 0.7903\n",
      "Epoch 5/10\n",
      "26/26 [==============================] - 12s 445ms/step - loss: 0.0880 - accuracy: 0.9782 - val_loss: 0.5467 - val_accuracy: 0.7823\n",
      "Epoch 6/10\n",
      "26/26 [==============================] - 12s 442ms/step - loss: 0.0703 - accuracy: 0.9817 - val_loss: 0.5556 - val_accuracy: 0.7957\n",
      "Epoch 7/10\n",
      "26/26 [==============================] - 12s 448ms/step - loss: 0.0550 - accuracy: 0.9849 - val_loss: 0.9709 - val_accuracy: 0.6882\n",
      "Epoch 8/10\n",
      "26/26 [==============================] - 12s 447ms/step - loss: 0.0324 - accuracy: 0.9917 - val_loss: 0.8011 - val_accuracy: 0.7097\n",
      "Epoch 9/10\n",
      "26/26 [==============================] - 12s 442ms/step - loss: 0.0318 - accuracy: 0.9905 - val_loss: 0.7271 - val_accuracy: 0.7608\n",
      "Epoch 10/10\n",
      "26/26 [==============================] - 11s 442ms/step - loss: 0.0350 - accuracy: 0.9909 - val_loss: 1.2306 - val_accuracy: 0.6694\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21134c79340>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(x_train,steps_per_epoch=len(x_train),epochs=10,validation_data=x_test,validation_steps=len(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5fd76d",
   "metadata": {},
   "source": [
    "# Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2eb73118",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('RPS.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10aaa0a6",
   "metadata": {},
   "source": [
    "# Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7bc01893",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "faf6b8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('RPS.h5')\n",
    "img = image.load_img(r'E:\\vitExternship\\DataSet\\RPS_Dataset\\Testing\\scissors\\testscissors01-07.png',target_size=(64,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c474f439",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=64x64 at 0x2113E9A4220>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1014e7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=image.img_to_array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "193c90a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[254., 254., 254.],\n",
       "        [254., 254., 254.],\n",
       "        [254., 254., 254.],\n",
       "        ...,\n",
       "        [252., 252., 252.],\n",
       "        [252., 252., 252.],\n",
       "        [253., 253., 253.]],\n",
       "\n",
       "       [[254., 254., 254.],\n",
       "        [254., 254., 254.],\n",
       "        [254., 254., 254.],\n",
       "        ...,\n",
       "        [252., 252., 252.],\n",
       "        [252., 252., 252.],\n",
       "        [251., 251., 251.]],\n",
       "\n",
       "       [[254., 254., 254.],\n",
       "        [253., 253., 253.],\n",
       "        [254., 254., 254.],\n",
       "        ...,\n",
       "        [252., 252., 252.],\n",
       "        [251., 251., 251.],\n",
       "        [251., 251., 251.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[251., 251., 251.],\n",
       "        [250., 250., 250.],\n",
       "        [250., 250., 250.],\n",
       "        ...,\n",
       "        [249., 249., 249.],\n",
       "        [249., 249., 249.],\n",
       "        [249., 249., 249.]],\n",
       "\n",
       "       [[251., 251., 251.],\n",
       "        [249., 249., 249.],\n",
       "        [251., 251., 251.],\n",
       "        ...,\n",
       "        [250., 250., 250.],\n",
       "        [250., 250., 250.],\n",
       "        [249., 249., 249.]],\n",
       "\n",
       "       [[250., 250., 250.],\n",
       "        [251., 251., 251.],\n",
       "        [251., 251., 251.],\n",
       "        ...,\n",
       "        [250., 250., 250.],\n",
       "        [248., 248., 248.],\n",
       "        [249., 249., 249.]]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d406607f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "895fbb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.expand_dims(x,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "927dcb63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "89ae3445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 74ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = np.argmax(model.predict(x),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cf92f259",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2], dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ca50f621",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = [\"Paper\",\"Rock\",\"Scissors\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3c23f790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scissors\n"
     ]
    }
   ],
   "source": [
    "print(index[pred[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccffa438",
   "metadata": {},
   "source": [
    "# CNN video Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da09256",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "model = load_model('RPS.h5')\n",
    "video = cv2.VideoCapture(0)\n",
    "index = [\"Paper\",\"Rock\",\"Scissors\"]\n",
    "while 1:\n",
    "    success,frame=video.read()\n",
    "    cv2.imwrite('RPS.jpg',frame)\n",
    "    img=image.load_img('RPS.jpg',target_size=(64,64))\n",
    "    x=image.img_to_array(img)\n",
    "    x=np.expand_dims(x,axis=0)\n",
    "    pred=np.argmax(model.predict(x),axis=1)\n",
    "    y=pred[0]\n",
    "    cv2.putText(frame,'The Predicted Symbol is: '+str(index[y]),(100,100),cv2.FONT_HERSHEY_SIMPLEX,1,(0,0,0),4)\n",
    "    cv2.imshow('image',frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c04d8f",
   "metadata": {},
   "source": [
    "# End of the Assignment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
